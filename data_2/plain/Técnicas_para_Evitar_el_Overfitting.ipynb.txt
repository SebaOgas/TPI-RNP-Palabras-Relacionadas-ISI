<a href="https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/DeepLearning/5EvaluacionModelos/3TecnicasOverfitting.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"/></a>

Técnicas para Evitar el Overfitting

Regularización de los pesos

Ahora que hemos caracterizado el problema del sobreajuste, podemos introducir algunas técnicas estándar para regularizar modelos. Recuerde que siempre podemos mitigar el sobreajuste saliendo y recopilando más datos de entrenamiento. Eso puede ser costoso, llevar mucho tiempo o estar completamente fuera de nuestro control, haciéndolo imposible a corto plazo. Por ahora, podemos asumir que ya tenemos tantos datos de alta calidad como nuestros recursos lo permitan y centrarnos en las técnicas de regularización.

Recuerde que en nuestro ejemplo de regresión polinomial podríamos limitar la capacidad de nuestro modelo simplemente modificando el grado del polinomio ajustado. De hecho, limitar el número de características es una técnica popular para mitigar el sobreajuste. Sin embargo, simplemente dejar de lado las características puede ser una medida demasiado drástica. Siguiendo con el ejemplo de regresión polinomial, considere lo que podría suceder con entradas de alta dimensión. Las extensiones naturales de polinomios a datos multivariados se denominan monomios, que son simplemente productos de potencias de variables. El grado de un monomio es la suma de las potencias. Por ejemplo,  y  son ambos monomios de grado 3.

Tenga en cuenta que el número de términos con grado  aumenta rápidamente a medida que  crece. Dadas las variables , el número de monomios de grado  es  (es decir,  multiselección ). Incluso pequeños cambios en el grado, digamos de  a , aumentan drásticamente la complejidad de nuestro modelo. Por lo tanto, a menudo necesitamos una herramienta más fina para ajustar la complejidad de la función.

Normas

Algunos de los operadores más útiles en álgebra lineal son normas. Informalmente, la norma de un vector nos dice cuán grande es un vector. La noción de tamaño que se considera aquí no se refiere a la dimensionalidad sino a la magnitud de los componentes.

Puede notar que las normas se parecen mucho a las medidas de distancia. De hecho, la distancia euclidiana es una norma: en concreto es la norma . Supongamos que los elementos en el vector -dimensional  son .

La norma  de  es la raíz cuadrada de la suma de los cuadrados de los elementos del vector:

donde el subíndice  a menudo se omite en las normas , es decir,  es equivalente a . En codigo,
podemos calcular la norma  de un vector de la siguiente manera.

En el aprendizaje profundo, trabajamos más a menudo con la norma  al cuadrado.

También encontrará con frecuencia la  norma , que se expresa como la suma de los valores absolutos de los elementos del vector:

En comparación con la norma , está menos influenciada por valores atípicos. Para calcular la norma , componemos la función de valor absoluto con una suma sobre los elementos.

Tanto la norma  como la norma  son casos especiales de la norma  más general:

De manera análoga a la norma  de los vectores, la norma de Frobenius de una matriz  es la raíz cuadrada de la suma de los cuadrados de los elementos de la matriz:

La norma de Frobenius satisface todas las propiedades de las normas vectoriales. Se comporta como si fuera una norma  de un vector en forma de matriz. Invocar la siguiente función calculará la norma de Frobenius de una matriz.

Regularizacion  (Weight Decay)

La regularización  podría ser la técnica más utilizada para regularizar modelos de aprendizaje automático paramétrico. La técnica está motivada por la intuición básica de que entre todas las funciones , la función  (que asigna el valor  a todas las entradas) es, en cierto sentido, la más simple, y que podemos medir la complejidad de una función por su distancia a cero. Pero, ¿con qué precisión debemos medir la distancia entre una función y cero? No hay una sola respuesta correcta. De hecho, ramas enteras de las matemáticas, incluidas partes del análisis funcional y la teoría de los espacios de Banach, están dedicadas a responder a este problema.

Una interpretación simple podría ser medir la complejidad de una función lineal  por alguna norma de su vector de peso, por ejemplo, . El método más común para asegurar un vector de peso pequeño es agregar su norma como término de penalización al problema de minimizar la pérdida. Por lo tanto, reemplazamos nuestro objetivo original, minimizar la pérdida de predicción en las etiquetas de entrenamiento, con un nuevo objetivo, minimizar la suma de la pérdida de predicción y el término de penalización. Ahora, si nuestro vector de peso crece demasiado, nuestro algoritmo de aprendizaje podría enfocarse en minimizar la norma de peso  vs. minimizar el error de entrenamiento. Eso es exactamente lo que queremos. Para ilustrar las cosas en el código, revivamos nuestro ejemplo anterior de la clase de regresión lineal. Allí, nuestra pérdida fue dada por

Recuerde que  son las características,  son etiquetas para todos los ejemplos de datos  y  son los parámetros de peso y sesgo, respectivamente. Para penalizar el tamaño del vector de peso, debemos agregar de alguna manera  a la función de pérdida, pero ¿cómo debería el modelo compensar la pérdida estándar por esta nueva penalización aditiva? En la práctica, caracterizamos esta compensación a través de la constante de regularización , un hiperparámetro no negativo que ajustamos usando datos de validación:

Para , recuperamos nuestra función de pérdida original. Para , restringimos el tamaño de . Dividimos por  por convención: cuando tomamos la derivada de una función cuadrática,  y  se cancelan, asegurando que la expresión para la actualización se vea bien y simple. El lector astuto podría preguntarse por qué trabajamos con la norma al cuadrado y no con la norma estándar (es decir, la distancia euclidiana). Hacemos esto por conveniencia computacional. Al elevar al cuadrado la norma , eliminamos la raíz cuadrada, dejando la suma de cuadrados de cada componente del vector de peso. Esto hace que la derivada de la penalización sea fácil de calcular: la suma de las derivadas es igual a la derivada de la suma.

El efecto logrado es el que se ve en el siguiente gráfico donde tenemos un ejemplo con 2 pesos w1 y w2 como ejes y un función de pérdida graficada como sus curvas de nivel. El círculo celeste representa la restricción establecida a los pesos por la regularización l2 y el circulito amarillo es la combinación de pesos elegida por el modelo. Podemos observar que el modelo se acerca lo más posible al mínimo de la función mientras sigue respetando la restricción de tamaño.

Además, podría preguntarse por qué trabajamos con la norma  en primer lugar y no, digamos, con la norma . Una razón para trabajar con la norma  es que impone una penalización descomunal a los pesos grandes del vector. Esto sesga nuestro algoritmo de aprendizaje hacia modelos que distribuyen el peso de manera uniforme entre una mayor cantidad de features. En la práctica, esto podría hacerlos más robustos al error de medición en una sola variable. Por el contrario, las penalizaciones de  conducen a modelos que concentran los pesos en un pequeño conjunto de características disminuyendo los otros pesos a cero. Esto se llama selección de características, lo que puede ser deseable por otras razones.

Regresión lineal de alta dimensión

Podemos ilustrar los beneficios de la pérdida de peso a través de un ejemplo sintético simple.

Primero, generamos algunos datos como antes

Elegimos que nuestra etiqueta sea una función lineal de nuestras entradas, alterada por el ruido gaussiano con media cero y desviación estándar de 0,01. Para que los efectos del sobreajuste sean pronunciados, podemos aumentar la dimensionalidad de nuestro problema a  y trabajar con un pequeño conjunto de entrenamiento que contiene solo 20 ejemplos. Reutilizaremos varias de las funciones que usamos en la clase 2 de regresión lineal.

Implementación desde cero

A continuación, implementaremos la regularización de los pesos desde cero, simplemente agregando la penalización de  al cuadrado a la función objetivo original.

Definiendo el modelo

Primero, definiremos un modelo de regresión lineal e inicializaremos aleatoriamente sus parámetros. Nótese que también agregamos un método loss que calcula el error cuadrático medio.

Definiendo la Norma de Penalización 

Quizás la forma más conveniente de implementar esta penalización es elevar al cuadrado todos los términos y sumarlos.

Modelo con Regularizacion

Ahora podemos implementar un modelo que calcule su pérdida regularizando los pesos con l2_penalty(). Para eso, definiremos un modelo que sea una subclase del que definimos más arriba y que redefina la función de pérdida.

Definición del ciclo de entrenamiento

El siguiente código ajusta un modelo en el conjunto de entrenamiento y lo evalúa en el conjunto de prueba.

Entrenando sin Regularización

Vamos a correr la función train() definida más arriba, pero con una constante de regularización igual a 0 (osea que la regularización no se llevará a cabo).

Nótese que se está produciendo un sobreajuste claro ya que el error de entrenamiento está decreciendo, pero el error de testeo se mantiene.

Entrenando con Regularización

Ahora usamos una constante de regularización distinta de 0. Nótese que el error de testeo está disminuyendo aunque el de entrenamiento no descienda tan bruscamente. Este es precisamente el efecto que esperamos de la regularización.

Implementación concisa

Debido a que la regularización de los pesos es omnipresente en la optimización de redes neuronales, Pytorch lo hace especialmente conveniente, ya que lo integra en el propio algoritmo de optimización para facilitar su uso en combinación con cualquier función de pérdida.

En el siguiente código, especificamos el hiperparámetro de regularización de pesos directamente a través de weightdecay al instanciar nuestro optimizador. De forma predeterminada, PyTorch regulariza tanto los pesos como los bias simultáneamente. Aquí solo establecemos weightdecay para el peso, por lo que el parámetro de bias b no se regularizará.

Las gráficas se ven idénticas a aquellas cuando implementamos la regularización de pesos desde cero. Sin embargo, funcionan considerablemente más rápido y son más fáciles de implementar, un beneficio que será más pronunciado para problemas más grandes.

Robustez a través de perturbaciones

Otra noción útil de simplicidad es la suavidad, es decir, que la función no debe ser sensible a pequeños cambios en sus entradas. Por ejemplo, cuando clasificamos imágenes, esperaríamos que agregar algo de ruido aleatorio a los píxeles sea en su mayoría inofensivo.

Cuando se entrena una red profunda con muchas capas, inyectar ruido a las entradas impone suavidad solo en el mapeo de entrada y salida. Si llevamos esta idea más allá e inyectamos ruido en cada capa de la red antes de calcular la capa subsiguiente durante el entrenamiento.

La idea, llamada dropout, consiste en inyectar ruido mientras se calcula cada capa interna durante el forward, y se ha convertido en una técnica estándar para entrenar redes neuronales. El método se llama dropout (abandono) porque literalmente abandona algunas neuronas durante el entrenamiento. A lo largo del entrenamiento, en cada iteración, el dropout estándar consiste en poner a cero una fracción de las neuronas en cada capa antes de calcular la capa siguiente.

El desafío clave entonces es cómo inyectar este ruido. Una idea es inyectar el ruido de una manera imparcial para que el valor esperado de cada capa, mientras se dejan fijas las otras, sea igual al valor que habría tomado sin el ruido.

En la regularización de dropout estándar, se elimina el sesgo de cada capa mediante la normalización por la fracción de nodos que se retuvieron (no se abandonaron). En otras palabras, con probabilidad de abandono , cada activación intermedia  se reemplaza por una variable aleatoria  de la siguiente manera:

Por diseño, la esperanza permanece sin cambios, es decir, .

Dropout en la práctica

El MLP con una capa oculta y 5 unidades ocultas que se ve en la figura del lado izquierdo, se transforma en el del lado derecho cuando aplicamos dropout sobre dicha capa, poniendo a cero cada unidad oculta con una probabilidad . El resultado puede verse como una red que contiene solo un subconjunto de las neuronas originales. En la figura, se eliminan  y . En consecuencia, el cálculo de las salidas ya no depende de  o  y su gradiente respectivo también se desvanece al realizar backpropagation. De esta manera, el cálculo de la capa de salida no puede depender demasiado de ningúnun elemento de .

Por lo general, deshabilitamos el abandono en el momento de la prueba. Dado un modelo entrenado y un nuevo ejemplo, no eliminamos ningún nodo y, por lo tanto, no necesitamos normalizar.

Implementación desde cero

Para implementar la función de dropout para una sola capa, debemos extraer tantas muestras de una variable aleatoria de Bernoulli (binaria) como dimensiones tenga nuestra capa, donde la variable aleatoria toma el valor  (mantener)
con probabilidad  y  (abandonar) con probabilidad . Una forma sencilla de implementar esto es extraer primero muestras de la distribución uniforme . Entonces podemos mantener aquellos nodos para los que la muestra correspondiente es mayor que , descartando el resto.

En el siguiente código, implementamos una función dropout_layer que descarta los elementos en la entrada del tensor X con probabilidad dropout, reescalando el resto como se describe arriba: dividiendo los sobrevivientes por 1.0-dropout.

Podemos probar la función dropout_layer en algunos ejemplos.
En las siguientes líneas de código, pasamos nuestra entrada X a través de la capa de dropout, con probabilidades 0, 0,5 y 1, respectivamente.

Definición de parámetros del modelo

Nuevamente, trabajamos con el conjunto de datos Fashion-MNIST. Definimos un MLP con dos capas ocultas que contienen 1024 unidades cada una.

Definición del modelo

El siguiente modelo aplica dropout a la salida de cada capa oculta (siguiendo la función de activación). Podemos establecer probabilidades de dropout para cada capa por separado. Una tendencia común es establecer una probabilidad de dropout más baja más cerca de la capa de entrada. A continuación, lo establecemos en 0.2 y 0.5 para la primera y segunda capa oculta, respectivamente. Nos aseguramos de que el dropout solo esté activo durante el entrenamiento.

Entrenamiento y Pruebas

Esto es similar al entrenamiento y prueba de los MLP descritos anteriormente.

Implementación concisa

Con las API de alto nivel, todo lo que tenemos que hacer es agregar una capa de 'Dropout' después de cada capa completamente conectada, pasando la probabilidad de dropout como único argumento a su constructor. Durante el entrenamiento, la capa "Dropout" eliminará aleatoriamente las salidas de la capa anterior (o de manera equivalente, las entradas de la capa posterior) de acuerdo con la probabilidad de dropout especificada. Cuando no está en modo de entrenamiento, la capa Dropout simplemente pasa los datos durante la prueba.

A continuación, entrenamos y probamos el modelo.