<a href="https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/CV/4TransferLearning/2_FineTuning.ipynb"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>

Fine-Tuning

En clases anteriores, discutimos cómo entrenar modelos en el dataset de entrenamiento Fashion-MNIST con solo 60000 imágenes. También describimos ImageNet, el dataset de imágenes a gran escala más utilizado en el mundo académico, que tiene más de 10 millones de imágenes y 1000 clases. Sin embargo, el tamaño de los dataset que solemos encontrar está entre medio de ambos.

Supongamos que queremos reconocer diferentes tipos de sillas a partir de imágenes y luego recomendar enlaces de compra a los usuarios. Un método posible es identificar primero 100 sillas comunes, tomar 1000 imágenes de diferentes ángulos para cada silla y luego entrenar un modelo de clasificación en el dataset de imágenes recopiladas. Aunque este dataset de sillas puede ser más grande que el dataset de Fashion-MNIST, la cantidad de ejemplos sigue siendo menos de una décima parte de la de ImageNet. Esto puede provocar el sobreajuste de modelos complicados que son adecuados para ImageNet en este dataset de silla. Además, debido a la cantidad limitada de ejemplos de entrenamiento, es posible que la precisión del modelo entrenado no cumpla con los requisitos prácticos.

Para abordar los problemas anteriores, una solución obvia es recopilar más datos. Sin embargo, recopilar y etiquetar datos puede requerir mucho tiempo y dinero. Por ejemplo, para recopilar el dataset de ImageNet, los investigadores han gastado millones de dólares en fondos de investigación. Aunque el costo actual de recopilación de datos se ha reducido significativamente, este costo aún no se puede ignorar.

Otra solución es aplicar el aprendizaje por transferencia (transfer learning) para transferir el conocimiento aprendido del dataset de origen al dataset de destino. Por ejemplo, aunque la mayoría de las imágenes en el dataset de ImageNet no tienen nada que ver con sillas, el modelo entrenado en este dataset puede extraer características de imagen más generales, lo que puede ayudar a identificar bordes, texturas, formas y composición de objetos. Estas características similares también pueden ser efectivas para reconocer sillas.

Pasos

En esta sección, presentaremos una técnica común en el aprendizaje por transferencia: fine tuning (ajuste fino). Como se muestra en la figura, el fine tuning consta de los siguientes cuatro pasos:

Entrene previamente un modelo de red neuronal, es decir, el modelo de origen, en un conjunto de datos de origen (por ejemplo, el conjunto de datos de ImageNet).
Cree un nuevo modelo de red neuronal, es decir, el modelo de destino. Este copia todo el diseño y los parámetros del modelo de origen excepto la capa de salida. Suponemos que estos parámetros del modelo contienen el conocimiento aprendido del conjunto de datos de origen y este conocimiento también será aplicable al conjunto de datos de destino. También suponemos que la capa de salida del modelo de origen está estrechamente relacionada con las etiquetas del conjunto de datos de origen; por lo tanto, no se utiliza en el modelo de destino.
Agregue una capa de salida al modelo de destino, cuyo número de salidas sea el número de clases en el conjunto de datos de destino. Luego inicialice aleatoriamente los parámetros del modelo de esta capa.
Entrene el modelo de destino en el conjunto de datos de destino, como un conjunto de datos de sillas. La capa de salida se entrenará desde cero, mientras que los parámetros de todas las demás capas se ajustarán en función de los parámetros del modelo de origen.

Cuando el conjunto de datos de destino es mucho más pequeño que el conjunto de datos de origen, el fine tuning ayuda a mejorar la capacidad de generalización de los modelos.

Reconocimiento de Hot Dogs

Demostremos el ajuste fino a través de un caso concreto: el reconocimiento de hot dogs. Haremos fine-tuning sobre  un modelo de ResNet, que se entrenó previamente en el conjunto de datos de ImageNet. Este fine tuning se hará con un pequeño conjunto de datos que consta de miles de imágenes con y sin hot dogs. Usaremos el modelo ajustado para reconocer hot dogs a partir de imágenes.

Lectura del dataset

El dataset de hot dogs que usamos se tomó de imágenes en línea. Este conjunto de datos consta de 1400 imágenes de clase positiva que contienen hot dogs y otras tantas imágenes de clase negativa que contienen otros alimentos. Se utilizan 1000 imágenes de ambas clases para entrenamiento y el resto para pruebas.

Después de descomprimir el conjunto de datos descargado, obtenemos dos carpetas hotdog/train y hotdog/test. Ambas carpetas tienen subcarpetas hotdog y not-hotdog, cualquiera de las cuales contiene imágenes de la clase correspondiente.

Creamos dos instancias para leer todos los archivos de imagen en el conjunto de datos de entrenamiento y prueba, respectivamente.

Los primeros 8 ejemplos positivos y las últimas 8 imágenes negativas se muestran a continuación. Como puede ver, las imágenes varían en tamaño y relación de aspecto.

Data Augmentation

Durante el entrenamiento, primero recortamos de la imagen un área aleatoria de tamaño aleatorio y relación de aspecto aleatoria, y luego escalamos esta área a una imagen de entrada de . Durante las pruebas, escalamos tanto el alto como el ancho de una imagen a 256 píxeles y luego recortamos un área central de  como entrada. Además, para los tres canales de color RGB (rojo, verde y azul) estandarizamos sus valores canal por canal. Concretamente, el valor medio de un canal se resta de cada valor de ese canal y luego el resultado se divide por la desviación estándar de ese canal.

Definición e inicialización del modelo

Usamos como modelo de origen a ResNet-18, que se entrenó previamente en el conjunto de datos de ImageNet. Aquí, especificamos pretrained=True para descargar automáticamente los parámetros del modelo previamente entrenado. Si este modelo se utiliza por primera vez, se requiere conexión a Internet para la descarga.

La instancia del modelo de origen previamente entrenada contiene varias capas de características y una capa de salida fc. El objetivo principal de esta división es facilitar el ajuste fino de los parámetros del modelo de todas las capas excepto la capa de salida. El atributo fc del modelo de origen se proporciona a continuación.

Como se trata de una capa densa, transforma los resultados de la capa de avg-pooling global final de ResNet en 1000 probabilidades de clase del conjunto de datos de ImageNet. Luego construimos una nueva red neuronal como modelo objetivo. Se define de la misma manera que el modelo de origen previamente entrenado, excepto que su número de salidas en la capa final se establece en el número de clases en el conjunto de datos de destino (en lugar de 1000).

En el siguiente código, los parámetros del modelo antes de la capa de salida de la instancia del modelo de destino finetune_net se inicializan en los parámetros del modelo de las capas correspondientes del modelo de origen. Dado que estos parámetros del modelo se obtuvieron mediante entrenamiento previo en ImageNet, son efectivos. Por lo tanto, solo podemos usar una pequeña tasa de aprendizaje para ajustar dichos parámetros previamente entrenados. Por el contrario, los parámetros del modelo en la capa de salida se inicializan aleatoriamente y generalmente requieren una mayor tasa de aprendizaje para aprender desde cero. Dejando que la tasa de aprendizaje base sea η, se utilizará una tasa de aprendizaje de 10η para iterar los parámetros del modelo en la capa de salida.

Haciendo el Fine-Tuning del modelo.

Primero, definimos una función de entrenamiento trainfinetuning para que pueda llamarse varias veces.

Establecemos la tasa de aprendizaje base en un valor pequeño para afinar los parámetros del modelo obtenidos a través del entrenamiento previo. Según la configuración anterior, entrenaremos los parámetros de la capa de salida del modelo de destino desde cero utilizando una tasa de aprendizaje diez veces mayor.

A modo de comparación, definimos un modelo idéntico, pero inicializamos todos sus parámetros de modelo a valores aleatorios. Dado que todo el modelo debe entrenarse desde cero, podemos usar una tasa de aprendizaje mayor.

Como podemos ver, el modelo ajustado tiende a funcionar mejor para la misma época porque los valores iniciales de sus parámetros son más efectivos.