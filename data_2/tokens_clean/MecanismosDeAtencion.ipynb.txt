Mecanismos
Atención
Queries
Keys
and
Values
Pensemos
bases
datos
forma
simple
colecciones
claves
valores
ejemplo
base
datos
consistir
tuplas
Zhang
Aston
Lipton
Zachary
Li
Mu
Smola
Alex
Hu
Rachel
Werness
Brent
apellido
clave
nombre
valor
operar
ejemplo
consulta
exacta
Li
devolvería
valor
Mu
Li
Mu
registro
habría
respuesta
válida
permitiéramos
coincidencias
aproximadas
recuperaríamos
Lipton
Zachary
lugar
ejemplo
simple
trivial
enseña
serie
cosas
útiles
diseñar
consultas
operen
pares
válidas
independientemente
tamaño
base
datos
consulta
recibir
respuestas
contenido
base
datos
código
ejecuta
operar
espacio
base
datos
simple
ejemplo
coincidencia
exacta
coincidencia
aproximada
top-
necesario
comprimir
simplificar
base
datos
operaciones
efectivas
Claramente
habríamos
introducido
base
datos
simple
propósito
explicar
aprendizaje
profundo
conduce
conceptos
interesantes
introducidos
aprendizaje
profundo
década
mecanismo
atención
simplemente
considere
base
datos
tuplas
claves
valores
denota
consulta
definir
atención
pesos
atención
escalares
operación
suele
denominar
agrupación
atención
nombre
atención
deriva
operación
presta
especial
atención
términos
peso
significativo
atención
genera
combinación
lineal
valores
contenidos
base
datos
contiene
ejemplo
caso
especial
pesos
cero
serie
casos
especiales
pesos
forman
combinación
convexa
configuración
común
aprendizaje
profundo
Exactamente
pesos
similar
consulta
base
datos
tradicional
pesos
iguales
equivale
promediar
base
datos
llamado
average
pooling
aprendizaje
profundo
estrategia
común
garantizar
pesos
sumen
normalizarlos
particular
garantizar
ponderaciones
negativas
recurrir
exponenciación
significa
elegir
función
aplicarle
operación
softmax
utilizada
modelos
multinomiales
operación
disponible
marcos
aprendizaje
profundo
diferenciable
gradiente
desaparece
propiedades
deseables
modelo
where
weights
are
derived
according
to
the
compatibility
between
query
and
keys
notable
código
real
ejecutar
conjunto
claves
valores
consulta
conciso
espacio
operar
significativo
propiedad
deseable
capa
red
requiere
demasiados
parámetros
aprender
conveniente
atención
operar
bases
datos
arbitrariamente
necesidad
cambiar
forma
realiza
operación
agrupación
atención
Visualización
beneficios
mecanismo
atención
intuitivo
particularmente
pesos
negativos
suman
caso
podríamos
interpretar
pesos
forma
modelo
seleccione
componentes
relevancia
intuición
importante
recordar
intuición
modos
queramos
visualizar
efecto
conjunto
claves
aplicar
variedad
consultas
función
útil
definimos
función
show_heatmaps
toma
matriz
pesos
atención
entrada
tensor
ejes
permite
variedad
consultas
pesos
consecuencia
matrices
entrada
forma
número
filas
mostrar
número
columnas
mostrar
número
consultas
número
claves
útil
queramos
visualizar
funcionamiento
diseño
Transformers
comprobación
rápida
cordura
visualicemos
matriz
identidad
representa
caso
peso
atención
consulta
clave
Atención
Producto
Punto
sección
dijimos
podíamos
elegir
función
aplicarle
operación
softmax
asegurar
pesos
atención
comportaran
distribuciones
probabilidad
sección
ejemplos
típicos
conocidas
Funciones
Puntuación
Atención
Attention
Scoring
Functions
Supongamos
elementos
consulta
clave
independientes
dibujan
aleatoriamente
forma
idéntica
variables
media
cero
varianza
unitaria
producto
escalar
vectores
media
cero
varianza
garantizar
varianza
producto
escalar
siga
independientemente
longitud
vector
utilizamos
función
puntuación
atención
producto
escalar
reescalamos
producto
escalar
Llegamos
función
atención
comúnmente
utilizada
utiliza
pesos
atención
necesitan
normalizarse
simplificar
Resulta
mecanismos
atención
populares
utilizan
softmax
limitaremos
resto
capítulo
Funciones
Útiles
Necesitamos
funciones
mecanismo
atención
eficiente
implementar
incluye
herramientas
manejar
cadenas
longitudes
variables
comunes
procesamiento
lenguaje
natural
herramientas
evaluación
eficiente
minibatches
multiplicación
matrices
lotes
Operación
Softmax
enmascarada
aplicaciones
populares
mecanismo
atención
modelos
procesan
secuencias
necesitamos
tratar
secuencias
longitudes
casos
dichas
secuencias
terminar
minibatch
requiere
rellenar
tokens
ficticios
secuencias
cortas
fichas
especiales
significado
ejemplo
supongamos
siguientes
oraciones
Dive
into
Deep
Learning
Learn
to
code
blank
Hello
world
blank
blank
modelo
preste
atención
espacios
blanco
simplemente
necesitamos
limitar
tamaño
real
oración
problema
común
nombre
operación
softmax
enmascarada
Implementémoslo
realidad
implementación
ligero
truco
establecer
valores
cero
establece
pesos
atención
número
negativo
contribución
gradientes
valores
desaparezca
práctica
núcleos
operadores
álgebra
lineal
optimizados
GPU
rápido
desperdiciar
cálculo
código
declaraciones
condicionales
if
then
else
ilustrar
funciona
función
considere
minilote
ejemplos
tamaño
longitudes
válidas
respectivamente
resultado
operación
softmax
enmascarada
valores
allá
longitudes
válidas
par
vectores
enmascaran
cero
necesitamos
control
detallado
especificar
longitud
válida
vectores
ejemplo
simplemente
tensor
bidimensional
longitudes
válidas
produce
Multiplicación
matrices
lotes
operación
comúnmente
utilizada
multiplicar
lotes
matrices
resulta
útil
minilotes
consultas
claves
valores
específicamente
supongamos
multiplicación
matrices
lotes
BMM
calcula
producto
elemento
elemento
Veamos
PyTorch
Implementación
Capa
Volvamos
atención
producto
introducida
general
requiere
consulta
clave
tengan
longitud
vector
digamos
solucionar
fácilmente
reemplazando
matriz
adecuadamente
elegida
traducir
espacios
supongamos
dimensiones
coinciden
práctica
pensamos
minilotes
lograr
eficiencia
calcular
atención
consultas
pares
clave-valor
consultas
claves
longitud
valores
longitud
atención
producto
escalar
escalado
consultas
claves
valores
escribir
aplicar
minibatch
necesitamos
multiplicación
matrices
lotes
introducida
anteriormente
implementación
atención
producto
escalado
utilizamos
dropout
regularización
modelo
ilustrar
funciona
clase
DotProductAttention
asumimos
tamaño
minibatch
claves
valores
dimensionalidad
valores
asumimos
longitud
válida
observación
respectivamente
esperamos
salida
tensor
fila
ejemplo
minibatch
comprobar
pesos
atención
realmente
desaparecen
cosa
allá
sexta
columna
respectivamente
establecer
longitud
válida
Atención
aditiva
consultas
claves
vectores
dimensión
matriz
abordar
discrepancia
atención
aditiva
función
puntuación
beneficio
nombre
indica
atención
aditiva
generar
ahorros
computacionales
menores
Dada
consulta
clave
función
puntuación
atención
aditiva
parámetros
aprender
término
introduce
softmax
garantizar
negatividad
normalización
Usando
función
activación
deshabilitando
términos
sesgo
implementamos
atención
aditiva
Veamos
funciona
AdditiveAttention
ejemplo
juguete
elegimos
consultas
claves
valores
tamaño
respectivamente
idéntico
elección
DotProductAttention
consultas
dimensión
elegimos
longitudes
válidas
secuencias
minibatch
revisar
función
atención
vemos
comportamiento
cualitativamente
similar
DotProductAttention
términos
longitud
válida
elegida
distintos
cero
