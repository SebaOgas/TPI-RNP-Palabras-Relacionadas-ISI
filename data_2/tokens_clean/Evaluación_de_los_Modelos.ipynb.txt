href="https://colab.research.google.com
github
institutohumai
cursos-python
blob
master
DeepLearning/5EvaluacionModelos/1Overfitting.ipynb
target="parent"><img
src="https://colab.research.google.com
assets
colab-badge.svg
alt="Open
in
Colab"/></a
Evaluación
Modelos
científicos
aprendizaje
automático
objetivo
descubrir
patrones
seguros
realmente
descubierto
patrón
general
simplemente
memorizado
datos
ejemplo
imagine
quisiéramos
buscar
patrones
marcadores
genéticos
vinculan
pacientes
demencia
etiquetas
extraen
conjunto
genes
persona
identifican
única
ignorando
hermanos
idénticos
memorizar
conjunto
datos
modelo
diga
Bob
recuerdo
demencia
razón
simple
implementemos
modelo
futuro
encontraremos
pacientes
modelo
visto
predicciones
útiles
modelo
realmente
descubierto
patrón
general
recapitular
formal
objetivo
descubrir
patrones
capturen
regularidades
población
subyacente
extrajo
conjunto
entrenamiento
éxito
esfuerzo
podríamos
evaluar
éxito
riesgo
personas
encontrado
problema
descubrir
patrones
generalizan
problema
fundamental
aprendizaje
automático
peligro
entrenamos
modelos
accedemos
pequeña
muestra
datos
conjuntos
datos
imágenes
públicas
contienen
millón
imágenes
debemos
aprender
miles
decenas
miles
ejemplos
datos
sistema
hospitalario
podríamos
acceder
cientos
miles
registros
médicos
trabajamos
muestras
finitas
corremos
riesgo
descubrir
asociaciones
aparentes
resultan
sostenerse
recopilamos
datos
fenómeno
ajustar
datos
entrenamiento
estrechamente
ajustamos
distribución
subyacente
denomina
sobreajuste
técnicas
utilizadas
combatir
sobreajuste
denominan
regularización
secciones
anteriores
observado
efecto
experimentaba
conjunto
datos
Fashion-MNIST
modificó
estructura
modelo
hiperparámetros
experimento
notado
suficientes
neuronas
capas
épocas
entrenamiento
modelo
finalmente
alcanzar
precisión
perfecta
conjunto
entrenamiento
precisión
datos
prueba
deteriora
Error
entrenamiento
error
generalización
discutir
fenómeno
formal
necesitamos
diferenciar
error
entrenamiento
error
generalización
error
entrenamiento
error
modelo
calculado
conjunto
entrenamiento
error
generalización
esperanza
error
modelo
aplicamos
flujo
infinito
ejemplos
datos
adicionales
extraídos
distribución
datos
subyacente
muestra
original
Problemáticamente
calcular
exactamente
error
generalización
flujo
datos
infinitos
objeto
imaginario
práctica
debemos
estimar
error
generalización
aplicando
modelo
conjunto
prueba
independiente
constituido
selección
aleatoria
ejemplos
datos
retenidos
conjunto
entrenamiento
varíen
errores
entrenamiento
generalización
siguientes
casos
modelo
obtenga
error
generalización
error
entrenamiento
mínimo
figura
vemos
mayoría
minimizar
error
entrenamiento
punto
volverlo
trae
aparejado
aumento
error
generalización
Componentes
Error
Generalización
error
generalización
esperanza
error
modelo
aplicamos
flujo
infinito
ejemplos
datos
adicionales
extraídos
distribución
datos
subyacente
muestra
original
expresamos
matemáticamente
quedaría
representa
esperanza
matemática
formaliza
idea
valor
fenómeno
aleatorio
par
artilugios
matemáticos
expresar
diferencia
predicción
dle
modelo
realidad
suma
términos
error
generalización
esperanza
diferencia
equivalente
suma
esperanzas
término
demostrar
esperanza
tercer
término
cero
permite
definir
error
generalización
componentes
principales
término
llama
Sesgo
Bias
inglés
llama
Varianza
resumen
error
generalización
siguientes
componentes
Sesgo
diferencia
predicción
esperada
promedio
modelo
valor
correcto
tratando
predecir
Varianza
variabilidad
esperada
promedio
predicción
modelo
Error
irreducible
error
introducido
marco
elegido
problema
causado
factores
features
tenidas
errores
medición
datos
resultar
extraño
hablar
error
promedio
modelos
modelo
imagine
pudiera
repetir
proceso
creación
modelo
recopilemos
datos
ejecutemos
entrenamiento
estaríamos
creando
modelo
aleatoriedad
conjuntos
datos
subyacentes
modelos
resultantes
variedad
predicciones
sesgo
mide
lejos
general
predicciones
modelos
valor
correcto
varianza
mide
lejos
general
predicciones
modelos
valor
predicciones
Sesgo
modelos
machine
learning
sesgo
aparece
suposiciones
simplistas
erróneas
hechas
modelo
función
objetivo
fácil
aprender
función
desea
aproximar
simple
comparada
función
real
modelo
capaz
aprender
producirá
underfitting
reducir
sesgo
aumentar
complejidad
modelo
Complejidad
modelo
constituye
precisamente
complejidad
modelo
asunto
complejo
factores
gobiernan
modelo
complejo
ejemplo
modelo
parámetros
considerarse
complejo
modelo
cuyos
parámetros
tomar
gama
amplia
valores
complejo
redes
neuronales
pensamos
modelo
toma
iteraciones
entrenamiento
complejo
sujeto
detención
anticipada
iteraciones
entrenamiento
complejo
Varianza
modelos
machine
learning
varianza
aparece
flexibilidad
excesiva
modelo
permite
ajustarse
ruido
presente
dataset
flexibilidad
consecuencia
complejidad
modelo
reducir
varianza
reducir
complejidad
Equilibrio
Sesgo
Varianza
complejidad
modelo
efectos
inversos
sesgo
varianza
problema
reduce
nuevamente
buscar
equilibrio
Ejemplo
polinomios
ilustrar
intuición
clásica
sobreajuste
complejidad
modelo
damos
ejemplo
usando
polinomios
Dados
datos
entrenamiento
consisten
característica
etiqueta
valor
real
correspondiente
tratamos
encontrar
polinomio
grado
estimar
etiquetas
problema
regresión
lineal
características
dadas
potencias
pesos
modelo
dados
sesgo
problema
regresión
lineal
error
cuadrático
función
pérdida
función
polinomial
orden
superior
compleja
función
polinomial
orden
inferior
polinomio
orden
superior
parámetros
rango
selección
función
modelo
amplio
corregir
conjunto
datos
entrenamiento
funciones
polinómicas
orden
superior
lograr
error
entrenamiento
menor
casos
relación
polinomios
grado
inferior
ejemplos
datos
tengan
valor
distinto
función
polinomial
grado
número
ejemplos
datos
ajustarse
perfectamente
conjunto
entrenamiento
explorar
conceptos
forma
interactiva
ajustando
polinomios
datos
Generación
dataset
necesitamos
datos
utilizaremos
polinomio
cúbico
generar
etiquetas
datos
entrenamiento
prueba
término
ruido
distribución
normal
media
desviación
estándar
0.1
optimización
normalmente
evitar
valores
gradientes
pérdidas
razón
características
reescalan
permite
evitar
valores
exponentes
Sintetizaremos
100
muestras
conjunto
entrenamiento
conjunto
prueba
Nuevamente
monomios
almacenados
poly_features
reescalados
función
gamma
Eche
vistazo
primeras
muestras
conjunto
datos
generado
valor
técnicamente
característica
característica
constante
correspondiente
sesgo
Entrenamiento
prueba
modelo
implementemos
función
evaluar
pérdida
conjunto
datos
definamos
función
entrenamiento
Ajuste
funciones
polinómicas
tercer
orden
normal
Comenzaremos
usando
función
polinomial
tercer
orden
orden
función
generación
datos
resultados
muestran
pérdidas
entrenamiento
prueba
modelo
reducirse
efectiva
parámetros
modelo
aprendido
cerca
valores
verdaderos
Ajuste
función
lineal
subajuste
underfitting
Echemos
vistazo
ajuste
funciones
lineales
declive
primeras
épocas
vuelve
difícil
disminuir
pérdida
entrenamiento
modelo
completada
iteración
época
pérdida
entrenamiento
alta
utilizan
ajustar
patrones
lineales
función
polinomial
tercer
orden
modelos
lineales
tienden
subajustar
Ajuste
funciones
polinómicas
orden
superior
sobreajuste
overfitting
intentemos
entrenar
modelo
usando
polinomio
grado
alto
datos
suficientes
coeficientes
grado
deberían
valores
cercanos
cero
resultado
modelo
excesivamente
complejo
susceptible
influenciado
ruido
datos
entrenamiento
pérdida
entrenamiento
reducir
efectiva
pérdida
prueba
Muestra
modelo
complejo
sobreajusta
datos
Discussions
