Transformers
Visión
ViT
arquitectura
tranformer
propuso
inicialmente
aprendizaje
secuencia
secuencia
traducción
automática
eficacia
tranformers
convirtieron
posteriormente
modelo
elección
diversas
tareas
procesamiento
lenguaje
natural
campo
visión
artificial
arquitectura
dominante
basado
CNN
adaptar
tranformers
modelar
datos
imagen
pregunta
despertado
interés
comunidad
visión
artificial
paper
2020
demostró
teóricamente
autoatención
aprender
comportarse
similar
convolución
Empíricamente
tomaron
parches
imágenes
entrada
pequeño
tamaño
parche
modelo
aplicable
datos
imágenes
resoluciones
bajas
restricciones
específicas
tamaño
parche
tranformers
visión
ViT
extraen
parches
imágenes
introducen
encoder
tranformer
obtener
representación
global
finalmente
transformará
clasificación
particular
tranformers
muestran
escalabilidad
CNN
entrenan
modelos
conjuntos
datos
tranformers
visión
superan
ResNet
margen
significativo
Similar
panorama
diseño
arquitectura
red
procesamiento
lenguaje
natural
tranformers
cambiaron
reglas
juego
visión
computadora
CNN
vs
ViT
Sesgo
Inductivo
sesgo
inductivo
término
utilizado
aprendizaje
automático
describir
conjunto
suposiciones
utiliza
algoritmo
aprendizaje
predicciones
términos
simples
sesgo
inductivo
atajo
ayuda
modelo
aprendizaje
automático
conjeturas
basadas
información
visto
par
sesgos
inductivos
observamos
CNN
Equivarianza
traslacional
objeto
aparecer
imagen
CNN
detectar
características
Localidad
píxeles
imagen
interactúan
principalmente
píxeles
circundantes
generar
features
sesgos
inductivos
ViT
originalmente
pensados
trabajar
secuencias
palabras
desempeñan
diseño
basado
mecanismos
atención
altamente
escalables
alto
grado
paralelización
superan
necesidad
sesgos
inductivos
entrena
cantidades
supermasivas
imágenes
Entrenando
ViT
cero
figura
representa
arquitectura
modelo
tranformers
visión
arquitectura
consta
base
parchea
imágenes
cuerpo
basado
encoder
tranformer
multicapa
cabeza
transforma
representación
global
etiqueta
salida
Considere
imagen
entrada
altura
ancho
canales
Especificando
altura
ancho
parche
imagen
divide
secuencia
parches
parche
aplana
vector
longitud
forma
parches
imagen
tratados
similar
tokens
secuencias
texto
encoderes
tranformeres
token
especial
lt;cls&gt
clasificación
parches
imagen
aplanados
proyectan
linealmente
secuencia
vectores
sumados
embeddings
posicionales
aprender
encoder
tranformer
multicapa
transforma
vectores
entrada
cantidad
representaciones
vectores
salida
longitud
Funciona
exactamente
encoder
tranformer
original
difiere
posición
normalización
token
lt;cls&gt
atiende
parches
imagen
autoatención
representación
salida
encoder
tranformer
transformará
etiqueta
salida
Patch
Embedding
implementar
transformer
visión
comencemos
embeddings
parches
Dividir
imagen
parches
proyectar
linealmente
parches
aplanados
simplificar
operación
convolución
tamaño
kernel
tamaño
stride
establecen
tamaño
parche
ejemplo
tomando
imágenes
altura
ancho
imgsize
entrada
generan
imgsize//patchsize)**2
parches
proyectan
linealmente
vectores
longitud
numhiddens
Encoder
Transformer
Vision
MLP
encoder
transformer
visión
ligeramente
red
feed
forward
posicional
encoder
transformer
original
función
activación
unidad
lineal
error
gaussiano
GELU
considerarse
versión
suave
ReLU
lugar
dropout
aplica
salida
capa
densa
MLP
regularización
implementación
bloque
encoder
transformer
visión
simplemente
diseño
prenormalización
normalización
aplica
justo
atención
multiples
cabezales
MLP
diferencia
posnormalización
normalización
coloca
justo
conexiones
residuales
prenormalización
conduce
entrenamiento
efectivo
eficiente
transformers
transformer
original
bloque
encoder
transformer
visión
cambia
forma
entrada
Juntar
paso
transformers
visión
sencillo
imágenes
entrada
introducen
instancia
PatchEmbedding
cuya
salida
concatena
embedding
token
lt;cls&gt
suman
embeddings
posicionales
aprendibles
dropout
salida
alimenta
encoder
transformer
apila
instancias
num_blks
clase
ViTBlock
Finalmente
representación
token
lt;cls&gt
token
proyectado
cabeza
red
Entrenamiento
Entrenar
transformer
visión
conjunto
datos
Fashion-MNIST
similar
entrenaron
CNN
clases
anteriores
notar
datasets
pequeños
Fashion-MNIST
transformer
visión
implementado
supera
ResNet
observaciones
similares
conjunto
datos
ImageNet
1,2
millones
imágenes
transformers
carecen
principios
útiles
convolución
localidad
invariancia
traslación
panorama
cambia
entrenan
modelos
datasets
ejemplo
300
millones
imágenes
transformers
visión
superan
ResNets
amplio
margen
clasificación
imágenes
demuestra
superioridad
intrínseca
transformers
escalabilidad
Fine
Tuning
ViT
pre-entrenado
fine-tuning
técnica
modelo
previamente
entrenado
aprendido
características
tarea
utiliza
punto
partida
tarea
similar
ahorra
tiempo
recursos
aprovechar
conocimiento
existente
modelo
lugar
entrenar
modelo
cero
sección
aplicar
fine-tuning
clasificación
imágenes
Vision
Transformer
dataset
elección
fine-tuning
necesitamos
actualizar
parámetros
modelo
ViT
aprendido
representaciones
características
millones
imágenes
optar
entrenar
capas
modelo
funcione
conjunto
datos
tutorial
usaremos
modelo
google
vit-base-patch16-224
Hugging
Face
hub
Comencemos
importando
módulos
funciones
necesarios
carguemos
dataset
clasificación
imágenes
tutorial
usaremos
dataset
mascotas
Oxford-IIIT
colección
imágenes
37
razas
perros
gatos
Usaremos
biblioteca
Hugging
Face
Datasets
cargar
conjunto
datos
fácilmente
hub
conjunto
datos
contiene
siguientes
características
ruta
ruta
archivo
etiqueta
raza
animal
perro
indica
animal
perro
imagen
imagen
formato
PIL
Veamos
imágenes
muestra
dataset
conjunto
datos
usemos
biblioteca
datasets
mezclarlo
usando
shuffle
seleccionar
muestra
usando
método
select
Preprocesamiento
conjunto
datos
datasets
imágenes
preprocesamiento
implica
pasos
incluye
transformaciones
cambiar
tamaño
imágenes
tengan
dimensiones
normalizar
escalar
valores
píxeles
rango
uniforme
augmentatio
imágenes
aplicando
giros
aleatorios
rotaciones
perspectivas
etc.
aplicar
transformaciones
dividamos
conjunto
datos
partes
entrenamiento
validación
conjunto
pruebas
oculto
evaluar
rendimiento
modelo
utilizar
método
incorporado
traintestsplit
división
entrenamiento
dataset
original
usaremos
80%
entrenamiento
10%
validación
10%
restante
división
prueba
importante
modelo
comprender
etiquetas
formato
string
asignamos
contrapartes
enteras
37
etiquetas
etiquetas
asignarán
número
36
Crearemos
asignaciones
label2id
id2label
convertir
etiquetas
ID
viceversa
útil
inicialicemos
modelo
actualizar
configuración
Image
Processor
aplicar
transformaciones
correctas
imágenes
usaremos
AutoImageProcessor
aplicará
transformaciones
modelo
usaremos
verificar
configuración
transformaciones
aplicarán
aplicar
transformaciones
lote
momento
entrenamiento
crear
función
preprocesará
lote
Trainer
llamará
función
agreguemos
conjunto
datos
usando
with_transform
momento
entrenamiento
debemos
aplicar
transformaciones
lote
muestras
manejar
lotes
crearemos
función
transforms
encargará
Convertir
imágenes
RGB
imágenes
conjunto
datos
escala
grises
transparentes
RGBA
Convertir
etiquetas
cadenas
números
enteros
usando
mapa
label2id
Aplicar
transformaciones
imágenes
pasamos
imágenes
processor
procesarlas
convertirlas
formato
PyTorch
características
conjunto
datos
resultantes
py
pixel_values
torch
Tensor
etiquetas
List
Emparejaremos
función
conjunto
datos
usando
método
with_transform
Data
Collation
proceso
agrupar
datos
formato
correcto
denomina
Data
Collation
pixel_values
forma
entrada
modelo
batch
channels
alto
ancho
labels
forma
batch
Veamos
calcular
métricas
utilizar
biblioteca
evaluate
Hugging
Face
calcular
métricas
clasificación
imágenes
utilizar
métrica
accuracy
Cargando
modelo
Usaremos
ViTForImageClassification
cargar
modelo
pre-entrenado
Necesitamos
actualizar
capa
clasificación
generar
predicciones
iguales
cantidad
etiquetas
conjunto
datos
haremos
pasando
argumento
num_labels
asignaciones
etiquetas
id2label
label2id
necesitamos
pasar
ignoremismatchedsizes
True
compensar
cambio
número
parámetros
capa
clasificación
arquitectura
modelo
actualizar
modelo
congelar
parámetros
capa
classifier
estableciendo
requires_grad
False
parámetros
capa
comprobar
parámetros
modelo
entrenar
Comencemos
entrenamiento
Hugging
Face
Trainer
entrenar
modelo
simple
elegir
argumentos
entrenamiento
tamaño
lote
tasa
aprendizaje
cantidad
épocas
opciones
logging
etc.
clasificación
imágenes
necesitamos
configurar
removeunusedcolumns
False
evitar
elimine
columna
image
conjunto
datos
utiliza
crear
entradas
pixel_values
Evaluamos
conjunto
datos
prueba
Veamos
predicciones
hechas
modelo
