href="https://colab.research.google.com
github
institutohumai
cursos-python
blob
master
CV/7ModelosGenerativos
GANs.ipynb
img
src='https://colab.research.google.com
assets
colab-badge.svg
/a
Redes
generativas
adversarias
curso
hablado
predicciones
forma
utilizamos
mapeos
aprendidos
redes
neuronales
profundas
ejemplos
datos
etiquetas
tipo
aprendizaje
llama
aprendizaje
discriminativo
gustaría
discriminar
fotos
gatos
fotos
perros
clasificadores
regresores
ejemplos
aprendizaje
discriminativo
redes
neuronales
entrenadas
backpropagation
revolucionado
creíamos
aprendizaje
discriminativo
conjuntos
datos
complicados
precisiones
clasificación
imágenes
alta
resolución
inútiles
niveles
humanos
salvedades
años
ahorraremos
perorata
tareas
discriminatorias
redes
neuronales
profundas
funcionan
asombrosamente
aprendizaje
automático
simplemente
resolver
tareas
discriminatorias
ejemplo
conjunto
datos
etiquetas
podríamos
querer
aprender
modelo
capture
concisa
características
datos
modelo
podríamos
muestrear
ejemplos
datos
sintéticos
asemejen
distribución
datos
entrenamiento
ejemplo
corpus
fotografías
rostros
queramos
generar
imagen
fotorrealista
parezca
plausible
provenga
conjunto
datos
tipo
aprendizaje
llama
modelado
generativo
teníamos
método
pudiera
sintetizar
imágenes
fotorrealistas
éxito
redes
neuronales
profundas
aprendizaje
discriminativo
abrió
posibilidades
tendencia
años
aplicación
redes
profundas
discriminatorias
superar
desafíos
problemas
generalmente
consideramos
problemas
aprendizaje
supervisado
modelos
lenguaje
redes
neuronales
recurrentes
ejemplo
red
discriminativa
entrenada
predecir
carácter
entrenada
actuar
modelo
generativo
2014
artículo
innovador
presentó
redes
adversarias
generativas
GAN
forma
inteligente
aprovechar
modelos
discriminativos
obtener
modelos
generativos
esencia
GAN
basan
idea
generador
datos
distinguir
datos
falsos
datos
reales
estadística
denomina
prueba
muestras
prueba
responder
pregunta
conjuntos
datos
extrajeron
distribución
principal
diferencia
mayoría
artículos
estadísticos
GAN
utilizan
idea
constructiva
palabras
lugar
simplemente
entrenar
modelo
diga
oiga
conjuntos
datos
parecen
provenir
distribución
prueba
muestras
proporcionar
señales
entrenamiento
modelo
generativo
permite
mejorar
generador
datos
genere
asemeje
datos
reales
mínimo
necesita
engañar
clasificador
clasificador
red
neuronal
profunda
generación
arquitectura
GAN
ilustra
figura
piezas
arquitectura
GAN
lugar
necesitamos
red
ssea
capaz
generar
datos
luzcan
cosa
real
tratando
imágenes
necesita
generar
imágenes
necesita
generar
secuencias
audio
sucesivamente
llamamos
red
generadora
componente
red
discriminadora
Intenta
distinguir
datos
falsos
reales
Ambas
redes
compiten
red
generadora
intenta
engañar
red
discriminadora
momento
red
discriminadora
adapta
datos
falsos
información
utiliza
mejorar
red
generadora
sucesivamente
discriminador
clasificador
binario
distinguir
entrada
real
datos
reales
falsa
generador
general
discriminador
genera
predicción
escalar
entrada
ejemplo
usando
capa
densa
neurona
aplica
función
sigmoidea
obtener
probabilidad
predicha
Suponga
etiqueta
datos
verdaderos
datos
falsos
Entrenamos
discriminador
minimizar
pérdida
entropía
cruzada
generador
extrae
parámetro
fuente
aleatoriedad
p.
ej.
distribución
normal
llamamos
variable
latente
aplica
función
generar
objetivo
generador
engañar
discriminador
clasificar
datos
verdaderos
palabras
discriminador
actualizamos
parámetros
generador
maximizar
pérdida
entropía
cruzada
generador
trabajo
perfecto
pérdida
acerca
resultado
gradientes
pequeños
progreso
discriminador
comúnmente
minimizamos
pérdida
alimentar
discriminador
dando
etiqueta
resumen
jugando
juego
minimax
función
objetivo
integral
aplicaciones
GAN
contexto
imágenes
demostración
contentar
ajustar
distribución
sencilla
Ilustraremos
sucede
GAN
construir
estimador
parámetros
ineficiente
mundo
gaussiano
Empecemos
Generando
datos
reales
ejemplo
lamentable
mundo
simplemente
generaremos
datos
extraídos
gaussiana
Let's
see
what
we
got
This
should
be
Gaussian
shifted
in
some
rather
arbitrary
way
with
mean
and
covariance
matrix
Generador
red
generadora
red
simple
modelo
lineal
capa
alimentaremos
red
lineal
generador
datos
gaussiano
literalmente
necesita
aprender
parámetros
falsificar
cosas
perfección
Discriminador
discriminador
seremos
discriminatorios
usaremos
MLP
capas
cosas
interesantes
Entrenamiento
definimos
función
actualizar
pesos
Discriminador
generador
actualiza
similar
reutilizamos
pérdida
entropía
cruzada
cambiamos
etiqueta
datos
falsos
discriminador
generador
realizan
regresión
logística
binaria
pérdida
entropía
cruzada
Adam
suavizar
proceso
entrenamiento
iteración
actualizamos
discriminador
generador
Visualizamos
pérdidas
ejemplos
generados
especificamos
hiperparámetros
ajusten
distribución
gaussiana
Redes
Generativas
Adversarias
Convolucionales
Profundas
DCGAN
sección
presentamos
ideas
básicas
funcionan
GAN
Mostramos
extraer
muestras
distribución
simple
fácil
muestrear
distribución
uniforme
normal
transformarlas
muestras
parecen
coincidir
distribución
conjunto
datos
ejemplo
coincidir
distribución
gaussiana
2D
entendió
punto
especialmente
emocionante
sección
demostraremos
GAN
generar
imágenes
Basaremos
modelos
GAN
convolucionales
profundas
DCGAN
presentadas
paper
Tomaremos
prestada
arquitectura
convolucional
demostrado
exitosa
problemas
discriminativos
visión
computadora
mostraremos
aprovechar
GAN
generar
imágenes
Dataset
FIFA
conjunto
datos
usaremos
colección
imágenes
jugadores
futbol
profesionales
obtenidos
sofifa.com
descarguemos
extraigamos
carguemos
conjunto
datos
Veamos
imágenes
dataset
Definimos
dataset
personalizado
imágenes
cargamos
dataloader
256
tamaño
lote
Generador
generador
necesita
mapear
variable
ruido
vector
longitud-
imagen
RGB
ancho
alto
bloque
básico
generador
contiene
capa
convolución
transpuesta
seguida
normalización
lotes
activación
ReLU
forma
predeterminada
capa
convolución
transpuesta
utiliza
kernel
stride
padding
entrada
forma
bloque
generador
duplicará
ancho
altura
entrada
cambia
kernel
capa
convolución
transpuesta
stride
padding
aumentará
tamaño
entrada
generador
consiste
bloques
básicos
aumentan
ancho
alto
entrada
32
tiempo
proyecta
variable
latente
canales
reduce
mitad
canales
utiliza
capa
convolución
transpuesta
generar
salida
Duplica
ancho
altura
coincida
forma
deseada
reduce
tamaño
canal
función
activación
tanh
aplica
valores
salida
proyecto
rango
Generemos
variable
latente
100
dimensiones
verificar
forma
salida
generador
Discriminador
discriminador
red
convolucional
normal
utiliza
Leaky
ReLU
función
activación
definición
verse
ReLU
normal
función
identidad
Leaky
ReLU
función
lineal
proporciona
salida
distinta
cero
entrada
negativa
objetivo
solucionar
problema
ReLU
moribunda
neurona
generar
valor
negativo
progreso
gradiente
ReLU
bloque
básico
discriminador
capa
convolución
seguida
capa
normalización
lotes
activación
Leaky
ReLU
hiperparámetros
capa
convolución
similares
capa
convolución
transpuesta
bloque
generador
bloque
básico
configuración
predeterminada
reducirá
mitad
ancho
alto
entradas
ejemplo
dada
entrada
forma
forma
kernel
stride
padding
forma
salida
discriminador
reflejo
generador
It
uses
convolution
layer
with
output
channel
as
the
last
layer
to
obtain
single
prediction
value
Entrenamiento
comparación
GAN
básico
vimos
tasa
aprendizaje
generador
discriminador
similares
cambiamos
Adam
Disminuye
suavidad
momentum
media
móvil
ponderada
exponencialmente
gradientes
anteriores
cuidar
gradientes
cambian
rápidamente
generador
discriminador
luchan
ruido
generado
aleatoriamente
tensor
4-D
usando
GPU
acelerar
cálculo
Entrenamos
modelo
pequeña
cantidad
épocas
demostración
rendimiento
variable
num_epochs
establecer
número
Predicción
entrenada
red
generar
imágenes
aleatorias
muestrear
vector
latente
pasarlo
generador
