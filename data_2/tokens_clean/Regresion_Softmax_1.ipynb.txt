href="https://colab.research.google.com
github
institutohumai
cursos-python
blob
master
DeepLearning/2RedesDeUnaCapa/2clasificacionsoftmax.ipynb
target="parent"><img
src="https://colab.research.google.com
assets
colab-badge.svg
alt="Open
in
Colab"/></a
Regresión
Softmax
dijimos
esperamos
llegar
sepas
regresión
logística
regresión
softmax
generalización
regresión
logística
clases
lugar
regresión
logística
técnica
apendizaje
automático
clasificación
binaria
típo
problemas
resultados
ejemplo
podríamos
interesados
tratar
predecir
persona
determinada
enfermedad
ejemplo
podríamos
considerar
serie
datos
siguientes
||temperatura|oxigenación|decaimiento|dolores|bultos
pulmones|presenta
enfermedad|
|---|:-:|:-:|:-:|:-:|:-:|:-:|
|paciente
1|
36.7|
0.88|
0|1|1|1|
|paciente
2|
38.0|
0.98|
1|0|0|0|
regresión
lineal
vimos
variables
repuesta
esperada
Presentamos
matriz
diseño
serie
valores
reales
grounding
truth
parametros
modelo
diferencia
regresión
logística
probabilidad
enfermo
podamos
regresión
lineal
problema
necesitamos
salida
probabilidad
necesitamos
entregar
valor
regresión
logística
modelo
forma
predicción
parametros
bias
principal
diferencia
valor
metemos
adentro
función
llamada
sigmodea
función
asegura
prediccion
probabilidad
diferencia
encontrar
parametros
usaremos
mínimos
cuadrados
herramienta
explicaremos
Dijimos
regresión
lineal
neurona
regresión
logística
neurona
principio
única
diferencia
salida
modelo
lineal
agregamos
función
adicional
pensar
regresión
logística
tipo
especial
neurona
recien
trabajamos
clases
proque
regresión
lógistica
permite
trabajar
clases
trabajaramos
clases
podríamos
seguir
pensando
neurona
red
neuronal
veremos
función
distinta
sigmoidea
función
llamada
Softmax
entregará
vector
numérico
componente
vector
corresponde
probabilidad
ejemplo
corresponde
clase
Presentando
problema
caso
haremos
implementación
implementación
usando
herrameintas
framework
dijimos
objetivo
perderle
miedo
frameworks
elegido
dataset
preexistente
conocido
FashionMNIST
datos
imágenes
píxeles
indumentaria
imagen
asociada
clase
10
clases
propuesta
clasificador
consistira
tomar
valores
píxeles
tratarlos
vectores
multiplicarlos
pesos
correspondiente
obtener
conjunto
valores
valores
probabilidad
pertenezcan
clases
definidas
datos
trabajando
imágenes
caso
features
valores
píxel
imagen
píxeles
features
estás
imágenes
indumentaria
etiquetas
correspondientes
clases
significa
matriz
pesos
tendra
tamaño
necesitar
10
neuronas
miren
píxeles
vean
traten
devolvernos
valores
transformaremos
probabilidades
trabajar
capa
neuronas
única
neurona
definido
pesos
lineal
modelo
necesitamos
definir
función
permita
convertir
salidas
probabilidades
función
análoga
hacía
sigmoidea
regresión
logística
función
función
softmax
Softmax
devuelve
vector
definición
componente
componente
suma
negativo
describen
vector
probabilidades
entrenamos
correctamente
probable
ejemplo
pertenezca
clase
demostrar
Softmax
clases
recupera
comportamiento
sigmoidea
sentido
generalización
clasificación
logística
Definiendo
softmax
figuras
anteriores
muestran
proceso
cálculo
Softmax
aplicamos
exponencial
salida
estimaciones
sumamos
ejemplo
representado
fila
dividimos
valor
obtenido
ejemplo
esimación
flechas
Inicialización
parámetros
Definiendo
softmax
implementación
perfecta
generar
problemas
numéricos
información
referimos
link
Definiendo
modelo
continuación
mostramos
ve
modelo
aplicar
sucesivas
operaciones
Entiende
reshape
entradas
aparecen
función
reshape
fondo
convertir
datos
conjunto
matrices
conjunto
vectores
Definiendo
función
pérdida
regresión
logística
función
pérdida
minimizar
entropía
cruzada
entropía
cruzada
propiedad
gradiente
función
Softmax
función
útil
continuación
discutiremos
utilidad
noción
entropía
estadística
relación
noción
información
Entropía
información
continuación
proponemos
juego
jugadores
Materiales
bolsa
recipiente
opaco
pelotas
números
Preparativos
colocan
pelotas
bolsa
jugador
saca
pelotas
bolsa
Objetivo
general
Adivinar
menor
número
preguntas
posibles
número
pelota
jugador
hacerse
preguntas
tengan
respuestas
dificil
juego
estrategia
optima
Preguntar
número
par
A.
respuesta
preguntar
número
a.
respuesta
número
ganado
b.
respuesta
número
ganado
B.
respuesta
preguntar
número
a.
respuesta
número
ganado
b.
respuesta
número
ganado
juego
fácil
solución
optima
copia
pelota
estrategia
cambiar
bolsa
hubieran
pelotas
distribución
pelotas
cambiara
punto
central
ejercicio
caso
categorías
equiprobables
necesitamos
preguntas
Veamos
||||||total|
|---|---|---|---|---|:-:|
|probabilidad
ocurrir|||||-|
|número
preguntas|||||-|
|producto||||||
Cambiemos
juego
Materiales
pelotas
números
cambiemos
distribución
pelotas
estrategia
optima
cambie
Preguntar
número
A.
respuesta
ganado
B.
respuesta
preguntar
número
a.
respuesta
ganado
b.
respuesta
preguntar
número
I.
respuesta
número
ganado
I.
respuesta
número
ganado
||||||total|
|---|---|---|---|---|:-:|
|probabilidad
ocurrir|||||-|
|número
preguntas|||||-|
|producto||||||
lector
perpicaz
debería
notar
siguientes
cosas
exactamente
analiza
árboles
deciciones
número
preguntas
corresponde
entropía
estadística
distribución
resultado
obtenido
similar
encontrar
código
Huffman
pelotas
relación
número
preguntas
distribuciones
lugar
noción
entropía
teoría
información
Shannon
Entropía
cruzada
pregunta
pasaría
jugadores
juego
tratara
jugar
pasa
estrategia
optima
juego
juego
paso
usaremos
número
preguntas
juego
probabilidad
||||||total|
|---|---|---|---|---|:-:|
|probabilidad
ocurrir|||||-|
|número
preguntas|||||-|
|producto||||||
número
promedio
preguntas
aumentado
parecer
mero
ejercicio
teórico
realidad
diciendo
general
clasificamos
conocemos
distribución
real
clases
problema
clasificador
implicitamente
supone
distribución
probabilistica
asociada
muestra
situación
creemos
juego
podríamos
juego
sentido
sentido
calcular
entropia
distribuciones
distintas
clasificador
datos
minimizamos
entropía
cruzada
modelo
reproduciendo
valores
reales
distribución
probabilística
modelo
datos
caso
pusimos
logaritmo
neperiano
lugar
logaritmo
base
fondo
irrelevante
fórmula
cambio
base
afecta
contante
multiplicativa
mínimo
Implementación
Entropía
Cruzada
forma
datos
serie
trucos
calcular
rápidamente
entropia
cruzada
facil
usando
one-hot
vectors
vale
clase
correcta
debemos
calcular
logaritmo
clase
correcta
Accuracy
general
tomamos
valor
alto
probabilidades
valor
correcto
trabajar
debemos
tratar
acertamos
predicciones
definimos
Accuracy
Definiendo
algoritmo
optimización
Tomamos
código
sgd
discutido
Entrenamiento
analicemos
haríamos
usando
herramientas
framework
Regresión
Softmax
concisa
código
revisaremos
identico
conocemos
Inicialización
Flatten
Convierte
matriz
píxeles
vector
números
Softmax
Dijimos
anterioremente
nuestre
implementación
Softmax
inestable
computacionalmente
razón
frameworks
preexistentes
implementaciones
evitan
inestabilidades
información
dejamos
link
LogSumExp
trick
Algoritmo
optimización
Entrenamiento
vemos
discutir
analizar
